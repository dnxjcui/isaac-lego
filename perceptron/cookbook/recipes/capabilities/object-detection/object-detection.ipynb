{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": "# Capability â€” PPE Detection\nLocate protective equipment on an assembly line and highlight every instance with normalized Perceptron geometry.\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ericpence/perceptron_repo/blob/main/cookbook/recipes/capabilities/object-detection/object-detection.ipynb)"
  },
  {
   "cell_type": "markdown",
   "id": "acae54e37e7d407bbb7b55eff062a284",
   "metadata": {},
   "source": "## Install dependencies\nInstall the SDK plus Pillow so we can preview grounded overlays."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a63283cbaf04dbcab1f6479b197f3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade perceptron pillow --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd0d8092fe74a7c96281538738b07e2",
   "metadata": {},
   "source": "## Configure the Perceptron client\nAuthenticate once, then resolve the PPE asset for the remaining cells."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eea5119410473aa328ad9291626812",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from IPython.display import Image as IPyImage\n",
    "from IPython.display import display\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "from cookbook.utils import cookbook_asset\n",
    "from perceptron import configure, image, perceive, text\n",
    "\n",
    "# configure() reads PERCEPTRON_API_KEY from the environment.\n",
    "configure(\n",
    "    provider=\"perceptron\",\n",
    "    # model=\"isaac-0.1\",  # Enable once the SDK supports the model argument.\n",
    ")\n",
    "\n",
    "SCENE_PATH = cookbook_asset(\"capabilities\", \"detection\", \"ppe_line.webp\")\n",
    "ANNOTATED_PATH = Path(\"ppe_line_annotated.png\")\n",
    "if not SCENE_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Missing asset: {SCENE_PATH}\")\n",
    "\n",
    "print(f\"Calling Perceptron | input={SCENE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edb47106e1a46a883d545849b8ab81b",
   "metadata": {},
   "source": "## Build a detection helper\nUse the `@perceive` decorator with `expects=\"box\"` so each detection returns normalized bounding boxes."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10185d26023b46108eb7d9f57d49d2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_CLASSES = [\"safety helmet\", \"safety vest\"]\n",
    "\n",
    "\n",
    "@perceive(expects=\"box\", allow_multiple=True)\n",
    "def detect_ppe(frame_path):\n",
    "    frame = image(frame_path)\n",
    "    classes_text = \", \".join(TARGET_CLASSES)\n",
    "    prompt = text(\n",
    "        \"Find every worker wearing PPE. Focus on helmets and high-visibility vests. \"\n",
    "        \"Return one bounding box per instance and include the item name in the mention attribute.\"\n",
    "    )\n",
    "    return frame + prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8763a12b2bbd4a93a75aff182afb95dc",
   "metadata": {},
   "source": "## Run the detection request\nInvoke the helper on the PPE line image to retrieve grounded regions."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7623eae2785240b9bd12b16a66d81610",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection = detect_ppe(str(SCENE_PATH))\n",
    "print(detection.text)\n",
    "boxes = detection.points or []\n",
    "print(f\"Returned {len(boxes)} boxes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdc8c89c7104fffa095e18ddfef8986",
   "metadata": {},
   "source": "## Render grounded results\nConvert the normalized coordinates to pixels and overlay them for quick inspection."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b118ea5561624da68c537baed56e602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(SCENE_PATH).convert(\"RGB\")\n",
    "draw = ImageDraw.Draw(img)\n",
    "\n",
    "\n",
    "def to_px(point):\n",
    "    return point.x / 1000 * img.width, point.y / 1000 * img.height\n",
    "\n",
    "\n",
    "for box in boxes:\n",
    "    top_left = to_px(box.top_left)\n",
    "    bottom_right = to_px(box.bottom_right)\n",
    "    draw.rectangle([top_left, bottom_right], outline=\"dodgerblue\", width=3)\n",
    "    draw.text(top_left, box.mention or \"ppe\", fill=\"dodgerblue\")\n",
    "\n",
    "img.save(ANNOTATED_PATH)\n",
    "display(IPyImage(filename=str(ANNOTATED_PATH)))\n",
    "print(f\"Saved annotated output to {ANNOTATED_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938c804e27f84196a10c8828c723f798",
   "metadata": {},
   "source": "## Conclusion & next steps\n- Adjust `TARGET_CLASSES` and the prompt to fit your environment.\n- Enable `stream=True` inside `@perceive` for incremental detections.\n- Add exemplar shots (see the in-context learning recipe) when classes are ambiguous."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
